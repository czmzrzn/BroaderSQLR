---
title: "BroaderSQLRData"
author: "Cameron B. Guy"
date: "2025-01-30"
output: html_document
---

```{r}
getwd()
library(revtools)
library(synthesisr)
library(dplyr)
library(janitor)
library(tidyverse)
library(stringr)
library(tidytext)
library(widyr)
library(ggraph)
library(ggplot2)
library(igraph)
library(base)
library(stm)
library(wordcloud)
library(writexl)
library(bibliometrix)
library(shiny)
library(topicmodels)
library(quanteda)
library(textstem)
library(stopwords)
```


```{r setup, include=FALSE}
#load in ris files and create a table with all data
ris_files <- list.files(path = "/Users/cameronguy/Documents/BROADSQLR", pattern = ".ris", full.names = TRUE)
data_raw <- read_refs(ris_files, return_df = TRUE, verbose = TRUE)
#8658 rows 42 columns
```
## Data wrangling

```{r data wrangling}
# make all column names & observations lowercase & remove italics characters from title
data_lowercase <- data_raw %>%
  clean_names() %>%
  mutate_all(.funs=tolower) %>%
  mutate(title = str_replace_all(title, "<i>", "")) %>%
  mutate(title = str_replace_all(title, "</i>", ""))

# complete missing values in source type column from zz
data_lowercase <- data_lowercase %>%
    mutate(source_type = ifelse(is.na(source_type) & str_detect(zz, "-"), zz, source_type)) %>%
    mutate(source_type = str_replace(source_type, "ty  - ", "")) %>%
    mutate(source_type = str_replace(source_type, "﻿", ""))

#update database column to include wos
data_lowercase <- data_lowercase %>%
  mutate(database = ifelse(is.na(database), "wos", "scopus"))

#remove unnecessary columns
data_wrangled <- select(data_lowercase, -c("a1", "ji", "j9", "c6", "date_generated", "supertaxa", "a2", "fu", "fx", "url", "accession_zr", "proceedings_title", "chemicals", "source_abbreviated", "zz", "filename", "source_abbreviated"))

#find and remove duplicates by doi
data_unique <- deduplicate(data_wrangled, "doi", method = "exact")
#8417 left - 241 removed

#find and remove duplicates within 5 different characters in title
data_unique2 <- deduplicate(data_unique, "title", method = "string_osa", threshold = 5)
#8341 left, another 76 removed

#rename to data for simplicity sake
data <- data_unique2

write.csv(data)
write_xlsx(data, "broaddata8417unique.xlsx")
write_bibliography(data, "database.ris", format = "ris")
```





```{r}
##ahhh get rid of na/empty abstracts
data <- data %>%
  filter(!is.na(abstract) & abstract != "")
write_xlsx(data, "broaddata8417unique.xlsx")
write_bibliography(data, "database.ris", format = "ris")
```

```{r}
##need to lematise
lexicon_url <- "https://raw.githubusercontent.com/michmech/lemmatization-lists/master/lemmatization-en.txt"
lexicon <- read_delim(lexicon_url, delim = "\t", col_names = c("word", "lemma"))

# Step 1: Clean HTML tags
data_clean <- data_clean %>%
  mutate(cleaned_abstract = gsub("<.*?>", "", cleaned_abstract))

# Step 2: Remove copyright statements
data_clean <- data_clean %>%
  mutate(cleaned_abstract = gsub("(?i)(©|copyright\\s*\\d{4}.*)", "", cleaned_abstract, perl = TRUE))

# Step 3: Remove short words (1 to 3 letters)
data_clean <- data_clean %>%
  mutate(cleaned_abstract = gsub("\\b\\w{1,3}\\b", "", cleaned_abstract))

# Step 4: Remove unwanted characters (e.g., punctuation, special symbols)
data_clean <- data_clean %>%
  mutate(cleaned_abstract = gsub("[^a-zA-Z\\s]", "", cleaned_abstract))

# Step 5: Trim extra spaces
data_clean <- data_clean %>%
  mutate(cleaned_abstract = trimws(gsub("\\s+", " ", cleaned_abstract)))

# Step 6: Remove numbers
data_clean <- data_clean %>%
  mutate(cleaned_abstract = gsub("[0-9]", "", cleaned_abstract))

# Now proceed with the tokenization, lemmatization, stopword removal, etc.
# Tokenize using tidytext's unnest_tokens (no need for quanteda tokens)
data_clean <- data_clean %>%
  unnest_tokens(word, cleaned_abstract)


# Remove default stopwords
data_clean <- data_clean %>%
  anti_join(stop_words, by = "word")

# Remove custom structural words
structural_words <- c("how", "may", "mays", "researches", "researcher", 
                      "researchers", "researched", "articles", "artcile",
                      "twos", "oughter" "method", "conclusion", "require", 
                      "result", "whiles", "arst", "mayed", "hows", "buts", 
                      "suggests", "suggest", "found", "founds", 
                      "article", "university", "study", "research", "find",
                      "data", "paper", "analyze", "examine", "investigate",
                      "but", "one", "two", "three", "four", "five", "six", 
                      "fours", "fourth", "seven", "eight", "nine", "ten", 
                      "zero", "while", "day", "days", "week", "weeks", 
                      "chapters", "common", "commonest", "chapter", "hundredth",
                      "important", "importance", "better", "betters", "authors",
                      "author", "eighth", "arst", "analysed", "humans", "tenth",
                      "human", "literature", "literatures", "focus", "foci", 
                      "focuses")

data_clean <- data_clean %>%
  filter(!(word %in% structural_words))

# Lemmatize using the lexicon
data_clean <- data_clean %>%
  left_join(lexicon, by = "word") %>%
  mutate(word = ifelse(is.na(lemma), word, lemma)) %>%
  select(-lemma)

# Reassemble cleaned text
data_clean <- data_clean %>%
  group_by(row_number()) %>%
  summarise(cleaned_abstract = paste(word, collapse = " "))

# Create bigrams (n = 2)
bigrams <- data_clean %>%
  unnest_tokens(ngram, cleaned_abstract, token = "ngrams", n = 2)

# Create trigrams (n = 3)
trigrams <- data_clean %>%
  unnest_tokens(ngram, cleaned_abstract, token = "ngrams", n = 3)

# Preview the output
head(bigrams)
head(trigrams)


dfm <- tokens %>%
  dfm() %>%
  dfm_trim(min_termfreq = 5)  # Remove rare terms

out <- convert(dfm, to = "stm")

stm_model <- stm(documents = out$documents, 
                 vocab = out$vocab, 
                 K = 6, 
                 data = out$meta, 
                 init.type = "LDA")

testlabeledtopics <- labelTopics(stm_model)
testlabeledtopics

testplot <- plot(stm_model, type = "summary", n = 6)
testplot

testcloud <- cloud(stm_model, topic = 7)
testcloud

```